{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1YFldAnIrvv"
   },
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# K.set_image_dim_ordering('tf')\n",
    "import os\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# from scipy.interpolate import griddata\n",
    "# from sklearn.preprocessing import scale\n",
    "# from functools import reduce\n",
    "# from keras.layers import Conv3D, MaxPool3D, Flatten, Dense, Conv2D, MaxPooling2D, Conv1D, MaxPool1D\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dropout, Input, BatchNormalization\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# # from plotly.offline import iplot, init_notebook_mode\n",
    "# from keras.losses import categorical_crossentropy\n",
    "# from keras.optimizers import Adadelta\n",
    "# # import plotly.graph_objs as go\n",
    "# # from matplotlib.pyplot import cm\n",
    "# # from keras.models import Model\n",
    "# import numpy as np\n",
    "\n",
    "# import keras\n",
    "# # import h5py\n",
    "# from keras.utils import to_categorical\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u97ekF2iMvSb"
   },
   "outputs": [],
   "source": [
    "# def make_matrix(df):\n",
    "# #     mat=np.array(df[1,:])\n",
    "#     return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfnZIdTcM7c_"
   },
   "outputs": [],
   "source": [
    "# def reformatInput(data, labels):\n",
    "#     indices = np.random.permutation(2131)\n",
    "\n",
    "#     trainIndices = [indices[:int(2131*.8)]]\n",
    "#     validIndices = [indices[int(2131*.8):]]\n",
    "\n",
    "#     if data.ndim == 3:\n",
    "#         return [(data[trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
    "#                 (data[validIndices], np.squeeze(labels[validIndices]).astype(np.int32))]\n",
    "# #                 (data[testIndices], np.squeeze(labels[testIndices]).astype(np.int32))]\n",
    "#     elif data.ndim == 5:\n",
    "#         return [(data[:, trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
    "#                 (data[:, validIndices], np.squeeze(labels[validIndices]).astype(np.int32))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcPXQ7mwM8LG"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "3laZgOVvNE8u",
    "outputId": "27426b5a-e3d7-4321-ef79-67d28dfba2bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>-0.753</td>\n",
       "      <td>5.74</td>\n",
       "      <td>16.800</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>22.6</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>2.320</td>\n",
       "      <td>1.71</td>\n",
       "      <td>-1.620</td>\n",
       "      <td>-7.060</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>42.70</td>\n",
       "      <td>42.70</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>52.3</td>\n",
       "      <td>20.50</td>\n",
       "      <td>-25.8</td>\n",
       "      <td>-25.8</td>\n",
       "      <td>20.50</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>5.940</td>\n",
       "      <td>24.60</td>\n",
       "      <td>-360.000</td>\n",
       "      <td>5.37</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.154</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.040</td>\n",
       "      <td>-2.930</td>\n",
       "      <td>...</td>\n",
       "      <td>211.00</td>\n",
       "      <td>-83.00</td>\n",
       "      <td>-83.00</td>\n",
       "      <td>211.00</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>-95.8</td>\n",
       "      <td>-95.8</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-21.900</td>\n",
       "      <td>-19.40</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-39.50</td>\n",
       "      <td>-56.2</td>\n",
       "      <td>-40.200</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>-94.70</td>\n",
       "      <td>-42.500</td>\n",
       "      <td>9.240</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.70</td>\n",
       "      <td>126.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>-41.70</td>\n",
       "      <td>-113.0</td>\n",
       "      <td>1.42</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1.42</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>31.100</td>\n",
       "      <td>31.70</td>\n",
       "      <td>32.900</td>\n",
       "      <td>29.40</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.960</td>\n",
       "      <td>2.090</td>\n",
       "      <td>-4.32</td>\n",
       "      <td>-2.230</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.87</td>\n",
       "      <td>8.37</td>\n",
       "      <td>8.37</td>\n",
       "      <td>-6.87</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5.48</td>\n",
       "      <td>-65.1</td>\n",
       "      <td>-65.1</td>\n",
       "      <td>5.48</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>10.500</td>\n",
       "      <td>31.40</td>\n",
       "      <td>-196.000</td>\n",
       "      <td>21.10</td>\n",
       "      <td>26.5</td>\n",
       "      <td>12.400</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>...</td>\n",
       "      <td>467.00</td>\n",
       "      <td>-146.00</td>\n",
       "      <td>-146.00</td>\n",
       "      <td>467.00</td>\n",
       "      <td>82.8</td>\n",
       "      <td>76.10</td>\n",
       "      <td>-27.4</td>\n",
       "      <td>-27.4</td>\n",
       "      <td>76.10</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  \\\n",
       "1887      -0.753      5.74    16.800    -10.90      22.6      -0.427   \n",
       "1379       5.940     24.60  -360.000      5.37      27.5       0.620   \n",
       "351      -21.900    -19.40    -0.952    -39.50     -56.2     -40.200   \n",
       "244       31.100     31.70    32.900     29.40      25.0      -1.960   \n",
       "1481      10.500     31.40  -196.000     21.10      26.5      12.400   \n",
       "\n",
       "      mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a    ...     fft_741_b  \\\n",
       "1887       2.320        1.71      -1.620      -7.060    ...         -3.96   \n",
       "1379       0.154        1.25       2.040      -2.930    ...        211.00   \n",
       "351       -0.511      -94.70     -42.500       9.240    ...        -41.70   \n",
       "244        2.090       -4.32      -2.230      -0.312    ...         -6.87   \n",
       "1481      -0.306       57.00       0.458      -2.790    ...        467.00   \n",
       "\n",
       "      fft_742_b  fft_743_b  fft_744_b  fft_745_b  fft_746_b  fft_747_b  \\\n",
       "1887      42.70      42.70      -3.96       52.3      20.50      -25.8   \n",
       "1379     -83.00     -83.00     211.00     -182.0     160.00      -95.8   \n",
       "351      126.00     126.00     -41.70     -113.0       1.42       23.4   \n",
       "244        8.37       8.37      -6.87      222.0       5.48      -65.1   \n",
       "1481    -146.00    -146.00     467.00       82.8      76.10      -27.4   \n",
       "\n",
       "      fft_748_b  fft_749_b     label  \n",
       "1887      -25.8      20.50  POSITIVE  \n",
       "1379      -95.8     160.00  NEGATIVE  \n",
       "351        23.4       1.42  POSITIVE  \n",
       "244       -65.1       5.48   NEUTRAL  \n",
       "1481      -27.4      76.10  NEGATIVE  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7e2nR6TINtJB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCUOxCBbNI5-"
   },
   "outputs": [],
   "source": [
    "df['label'].replace(['POSITIVE', 'NEUTRAL','NEGATIVE'],[2,1,0], inplace= True )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "zvc7_fmKODHG",
    "outputId": "1e631848-bd56-4347-be73-28787d77b869"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-4.43</td>\n",
       "      <td>6.07</td>\n",
       "      <td>22.1</td>\n",
       "      <td>-12.90</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>-2.220</td>\n",
       "      <td>3.110</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-2.88</td>\n",
       "      <td>...</td>\n",
       "      <td>12.800</td>\n",
       "      <td>-12.800</td>\n",
       "      <td>-12.800</td>\n",
       "      <td>12.800</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.54</td>\n",
       "      <td>-19.3</td>\n",
       "      <td>-19.3</td>\n",
       "      <td>7.54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>13.30</td>\n",
       "      <td>24.70</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>12.70</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>1.860</td>\n",
       "      <td>-3.700</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>-6.59</td>\n",
       "      <td>...</td>\n",
       "      <td>-166.000</td>\n",
       "      <td>50.900</td>\n",
       "      <td>50.900</td>\n",
       "      <td>-166.000</td>\n",
       "      <td>-52.9</td>\n",
       "      <td>26.70</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>26.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>14.00</td>\n",
       "      <td>22.90</td>\n",
       "      <td>-268.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>26.2</td>\n",
       "      <td>1.8000</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-2.760</td>\n",
       "      <td>2.31</td>\n",
       "      <td>3.86</td>\n",
       "      <td>...</td>\n",
       "      <td>237.000</td>\n",
       "      <td>-65.800</td>\n",
       "      <td>-65.800</td>\n",
       "      <td>237.000</td>\n",
       "      <td>83.2</td>\n",
       "      <td>28.20</td>\n",
       "      <td>-34.2</td>\n",
       "      <td>-34.2</td>\n",
       "      <td>28.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>29.30</td>\n",
       "      <td>28.80</td>\n",
       "      <td>30.3</td>\n",
       "      <td>29.20</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1.2900</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.396</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>...</td>\n",
       "      <td>12.500</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>12.500</td>\n",
       "      <td>212.0</td>\n",
       "      <td>35.10</td>\n",
       "      <td>-69.7</td>\n",
       "      <td>-69.7</td>\n",
       "      <td>35.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>26.20</td>\n",
       "      <td>31.20</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.90</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-7.8700</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>9.500</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>-6.88</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>121.0</td>\n",
       "      <td>11.20</td>\n",
       "      <td>31.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>11.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  \\\n",
       "184        -4.43      6.07      22.1    -12.90      23.3      0.0727   \n",
       "1567       13.30     24.70    -128.0     12.70      27.7      0.1560   \n",
       "1935       14.00     22.90    -268.0      8.38      26.2      1.8000   \n",
       "459        29.30     28.80      30.3     29.20      25.7      1.2900   \n",
       "1814       26.20     31.20      29.4     24.90      26.0     -7.8700   \n",
       "\n",
       "      mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a  ...    fft_741_b  \\\n",
       "184       -2.220       3.110        1.05       -2.88  ...       12.800   \n",
       "1567       1.860      -3.700       -3.58       -6.59  ...     -166.000   \n",
       "1935       0.699      -2.760        2.31        3.86  ...      237.000   \n",
       "459        0.638       0.396        1.97       -1.34  ...       12.500   \n",
       "1814      -0.724       9.500       -6.24       -6.88  ...       -0.291   \n",
       "\n",
       "      fft_742_b  fft_743_b  fft_744_b  fft_745_b  fft_746_b  fft_747_b  \\\n",
       "184     -12.800    -12.800     12.800      106.0       7.54      -19.3   \n",
       "1567     50.900     50.900   -166.000      -52.9      26.70       10.9   \n",
       "1935    -65.800    -65.800    237.000       83.2      28.20      -34.2   \n",
       "459      -2.600     -2.600     12.500      212.0      35.10      -69.7   \n",
       "1814      0.134      0.134     -0.291      121.0      11.20       31.7   \n",
       "\n",
       "      fft_748_b  fft_749_b  label  \n",
       "184       -19.3       7.54      2  \n",
       "1567       10.9      26.70      0  \n",
       "1935      -34.2      28.20      0  \n",
       "459       -69.7      35.10      1  \n",
       "1814       31.7      11.20      1  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-VGkrQfxOwlP",
    "outputId": "1e54553c-5c17-4f02-c3ec-0f35347c0244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2132 entries, 0 to 2131\n",
      "Columns: 2548 entries, # mean_0_a to fft_749_b\n",
      "dtypes: float64(2548)\n",
      "memory usage: 41.4 MB\n"
     ]
    }
   ],
   "source": [
    "dftrain=df.iloc[:,:-1]\n",
    "dftest=df.iloc[:,-1]\n",
    "dftrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsWqXD6sOQbe"
   },
   "outputs": [],
   "source": [
    "# dftrain=make_matrix(dftrain)\n",
    "# dftest=make_matrix(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thgmOupWOYkG"
   },
   "outputs": [],
   "source": [
    "# dftrain=np.asarray(df)\n",
    "# dftest=np.asarray(dftest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "61yuD1mhOaDu",
    "outputId": "5b4f1844-301e-43f8-d17e-997232ff8fdc"
   },
   "outputs": [],
   "source": [
    "# print(dftrain.shape)\n",
    "# print('*'*100)\n",
    "# print(dftest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lRl7hGlZVIoo",
    "outputId": "989d703b-3017-46d0-a4b4-000bdae2019a"
   },
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train,y_test= train_test_split(dftrain,dftest,test_size=.20, random_state=0)\n",
    "# X_train.shape\n",
    "# X_test.shape\n",
    "# # y_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUjU3QwClL8O"
   },
   "outputs": [],
   "source": [
    "# n_cols = X_train.shape[1]\n",
    "# model_mc = Sequential()\n",
    "\n",
    "# #add model layers\n",
    "# model_mc.add(Dense(500, activation='relu', input_shape=(n_cols,)))\n",
    "# model_mc.add(Dense(400, activation='relu'))\n",
    "# model_mc.add(Dense(300, activation='relu'))\n",
    "# model_mc.add(Dense(1))\n",
    "\n",
    "# #compile model using mse as a measure of model performance\n",
    "# model_mc.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "# #train model\n",
    "# model_mc.fit(X_train, y_train, validation_split=0.2, epochs=30, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8x-nk8ZQWjnn"
   },
   "outputs": [],
   "source": [
    "# X_train=X_train.reshape(1705,2549)\n",
    "# print(X_train.shape)\n",
    "# X_test=X_test.reshape(427,2549)\n",
    "# print(X_test.shape)\n",
    "# fit and evaluate a model\n",
    "# def evaluate_model(trainX, trainy, testX, testy):\n",
    "# \tverbose, epochs, batch_size = 0, 10, 32\n",
    "# \tn_timesteps, n_features, n_outputs = trainX.shape[0], trainX.shape[1], trainy.shape[0]\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(2549,1)))\n",
    "# # \tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "# # \tmodel.add(Dropout(0.5))\n",
    "# # \tmodel.add(MaxPool1D(pool_size=2))\n",
    "# \tmodel.add(Flatten())\n",
    "# \tmodel.add(Dense(100, activation='relu'))\n",
    "# \tmodel.add(Dense(3, activation='softmax'))\n",
    "# \tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# \t# fit network\n",
    "# \tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# \t# evaluate model\n",
    "# \t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "# \treturn accuracy\n",
    "# ans= evaluate_model(X_train, y_train, X_test, y_test)\n",
    "# # fit and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5t4pooAOkZG"
   },
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# K.set_image_dim_ordering('tf')\n",
    "# def make_model():\n",
    "  \n",
    "#   num_category = 2\n",
    "#   # t_train=y_train\n",
    "#   # y_test=y_val\n",
    "#   # y_train = keras.utils.to_categorical(y_train, num_category)\n",
    "#   # y_test = keras.utils.to_categorical(y_val, num_category)\n",
    "#   model = Sequential()\n",
    "#   #convolutional layer with rectified linear unit activation\n",
    "#   model.add(Conv1D(32, kernel_size=3,\n",
    "#                    activation='relu'))\n",
    "#   #32 convolution filters used each of size 3x3\n",
    "#   #again\n",
    "#   model.add(MaxPooling1D(pool_size=2))\n",
    "#   model.add(BatchNormalization())\n",
    "#   model.add(Dropout(0.1))\n",
    "#   model.add(Conv1D(64, 3, activation='relu'))\n",
    "#   #64 convolution filters used each of size 3x3\n",
    "#   #choose the best features via pooling\n",
    "#   model.add(MaxPooling1D(pool_size=2))\n",
    "#   model.add(BatchNormalization())\n",
    "#   model.add(Dropout(0.2))\n",
    "#   model.add(Conv1D(128, kernel_size=3,\n",
    "#   #                  activation='relu'))\n",
    "#   model.add(MaxPooling1D(pool_size=2))\n",
    "# #   model.add(BatchNormalization())\n",
    "#   model.add(Dropout(0.2))\n",
    "#   # randomly turn neurons on and off to improve convergence\n",
    "#   # model.add(Dropout(0.25))\n",
    "#   # model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "#   # #64 convolution filters used each of size 3x3\n",
    "#   # #choose the best features via pooling\n",
    "#   # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#   # model.add(BatchNormalization())\n",
    "#   # model.add(Dropout(0.2))\n",
    "#   # model.add(Conv2D(512, kernel_size=(3, 3),\n",
    "#   #                  activation='relu'))\n",
    "#   # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#   # model.add(BatchNormalization())\n",
    "#   # model.add(Dropout(0.1))\n",
    "#   # # randomly turn neurons on and off to improve convergence\n",
    "#   # model.add(Dropout(0.25))\n",
    "#   # # flatten since too many dimensions, we only want a classification output\n",
    "#   model.add(Flatten())\n",
    "#   #fully connected to get all relevant data\n",
    "#   model.add(Dense(128, activation='relu'))\n",
    "#   #one more dropout for convergence' sake :) \n",
    "#   model.add(Dropout(0.2))\n",
    "#   #output a softmax to squash the matrix into output probabilities\n",
    "#   model.add(Dense(num_category, activation='softmax'))\n",
    "#   print(model.summary())\n",
    "#   model.compile(loss=keras.losses.binary_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adam(.0001),\n",
    "#               metrics=['accuracy'])\n",
    "#   return model\n",
    "# model=make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZ7tBs8eSSr2"
   },
   "outputs": [],
   "source": [
    "#machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split #to create validation data set\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_training, X_valid, y_training, y_valid = train_test_split(dftrain, dftest, test_size=0.20, random_state=0)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components = 3)\n",
    "# X_training = pca.fit_transform(X_training)\n",
    "# X_valid = pca.transform(X_valid)\n",
    "# explained_variance = pca.explained_variance_ratio_\n",
    "# print (explained_variance)\n",
    "\n",
    "# from sklearn import svm\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # X,y, nfolds= X_train, y_train,10\n",
    "# def svc_param_selection(X, y, nfolds):\n",
    "#   Cs = [2**-10,2**-8,2**-6,2**-4,2**-2,2**0,2**2,2**4,2**6,2**8,2**10]\n",
    "#   gammas = [2**-10,2**-8,2**-6,2**-4,2**-2,2**0,2**2,2**4,2**6,2**8,2**10]\n",
    "#   param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "#   grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "#   grid_search.fit(X, y)\n",
    "#   grid_search.best_params_\n",
    "#   return grid_search\n",
    "# s= svc_param_selection(X_training, y_training, nfolds=10)\n",
    "\n",
    "# s.fit(X_training,y_training)\n",
    "# pred_rf = s.predict(X_valid)\n",
    "# acc_rf = accuracy_score(y_valid, pred_rf)\n",
    "# print(acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "7tn_9YHGBDRg",
    "outputId": "bbeacd4b-46ab-43a5-ad7e-a93d8782f723"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d56ac7aa77c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrf_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpred_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0macc_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    698\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1045\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rf_clf = RandomForestClassifier()\n",
    "rf_clf = XGBClassifier()\n",
    "\n",
    "rf_clf.fit(X_training, y_training)\n",
    "pred_rf = rf_clf.predict(X_valid)\n",
    "acc_rf = accuracy_score(y_valid, pred_rf)\n",
    "print(acc_rf)\n",
    "# pred_rf\n",
    "\n",
    "# rf_clf = RandomForestClassifier()\n",
    "\n",
    "# parameters = {\"n_estimators\": [4, 5, 6, 7, 8, 9, 10, 15], \n",
    "#               \"criterion\": [\"gini\", \"entropy\"],\n",
    "#               \"max_features\": [\"auto\", \"sqrt\", \"log2\"], \n",
    "#               \"max_depth\": [2, 3, 5, 10], \n",
    "#               \"min_samples_split\": [10],\n",
    "#               \"min_samples_leaf\": [1, 5, 8, 10]\n",
    "#              }\n",
    "\n",
    "# grid_cv = GridSearchCV(rf_clf, parameters, scoring = make_scorer(accuracy_score))\n",
    "# grid_cv = grid_cv.fit(X_training, y_training)\n",
    "\n",
    "# print(\"Our optimized Random Forest model is:\")\n",
    "# grid_cv.best_estimator_\n",
    "\n",
    "# rf_clf = grid_cv.best_estimator_\n",
    "# rf_clf.fit(X_training, y_training)\n",
    "# pred_rf = rf_clf.predict(X_valid)\n",
    "# acc_rf = accuracy_score(y_valid, pred_rf)\n",
    "# print(acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnXq4YjnDxQd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "emotiondataset.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
