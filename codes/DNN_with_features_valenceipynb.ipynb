{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN with features_valenceipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quirkyabhi/EEG-EMOTIONAL-ANALYSIS/blob/master/codes/DNN_with_features_valenceipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuIa2esZi0-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('tf')\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "from scipy.interpolate import griddata\n",
        "from sklearn.preprocessing import scale\n",
        "from functools import reduce\n",
        "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense, Conv2D, MaxPooling2D, Conv1D, MaxPool1D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Input, BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "# from plotly.offline import iplot, init_notebook_mode\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adadelta\n",
        "# import plotly.graph_objs as go\n",
        "# from matplotlib.pyplot import cm\n",
        "# from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "# import h5py\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDXuAd5OSXUz",
        "colab_type": "code",
        "outputId": "f6586c1a-55ac-47ad-918d-9b922e339d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmy2ZiwRjC6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def reformatInput(data, labels):\n",
        "#     indices = np.random.permutation(147200)\n",
        "\n",
        "#     trainIndices = [indices[:int(147200*.8)]]\n",
        "#     validIndices = [indices[int(147200*.8):]]\n",
        "\n",
        "#     if data.ndim == 3:\n",
        "#         return [(data[trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
        "#                 (data[validIndices], np.squeeze(labels[validIndices]).astype(np.int32))]\n",
        "# #                 (data[testIndices], np.squeeze(labels[testIndices]).astype(np.int32))]\n",
        "#     elif data.ndim == 5:\n",
        "#         return [(data[:, trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
        "#                 (data[:, validIndices], np.squeeze(labels[validIndices]).astype(np.int32))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WADMpjU9jHtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def make_matrix(df):\n",
        "    mat=np.array(df[1,:])\n",
        "    return df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiRJpThHjHwW",
        "colab_type": "code",
        "outputId": "0226f0df-fc8f-4c01-851e-e9613a847069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df=pd.read_csv('multilabel_feature.csv',  header=None, nrows=1280)\n",
        "#ldf=pd.read_csv('drive/My Drive/EEG1/arousal_label_big.csv', header= None, nrows=147200)\n",
        "# mat=make_matrix(df)\n",
        "# ldf=make_matrix(ldf)\n",
        "#ldf=np.asarray(ldf)\n",
        "# mat.shape\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE07jbdujKSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " X_train=df.iloc[:,:-1]\n",
        " y_train=df.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFZ59UXDjKpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(len(mat)):\n",
        "#     finalmat.append(mat[i,:].reshape(-1,384))\n",
        "# train=np.asarray(finalmat)\n",
        "# train.shape\n",
        "# finalmat[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-IWsuR-jKr0",
        "colab_type": "code",
        "outputId": "99f18acc-dca6-416c-ea05-4d0241bf1926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# (X_train, y_train), (X_test, y_test) = reformatInput(train, ldf)\n",
        "# # y_train=to_categorical(y_train)\n",
        "# # y_test=to_categorical(y_test)\n",
        "# X_train = X_train.astype(float).reshape(117760,32,32,1)\n",
        "# X_test = X_test.astype(float).reshape(147200-117760,32,32,1)\n",
        "X_train=df.astype(float)\n",
        "y_train=np.squeeze(y_train.astype(np.int32))\n",
        "y_train.shape\n",
        "X_train.shape\n",
        "# y_train = keras.utils.to_categorical(y_train)\n",
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       2\n",
              "5       2\n",
              "6       2\n",
              "7       2\n",
              "8       4\n",
              "9       3\n",
              "10      4\n",
              "11      4\n",
              "12      4\n",
              "13      4\n",
              "14      3\n",
              "15      1\n",
              "16      3\n",
              "17      1\n",
              "18      1\n",
              "19      1\n",
              "20      1\n",
              "21      2\n",
              "22      2\n",
              "23      1\n",
              "24      1\n",
              "25      1\n",
              "26      1\n",
              "27      4\n",
              "28      4\n",
              "29      4\n",
              "       ..\n",
              "1250    1\n",
              "1251    2\n",
              "1252    2\n",
              "1253    1\n",
              "1254    2\n",
              "1255    3\n",
              "1256    1\n",
              "1257    1\n",
              "1258    1\n",
              "1259    2\n",
              "1260    3\n",
              "1261    3\n",
              "1262    3\n",
              "1263    3\n",
              "1264    3\n",
              "1265    2\n",
              "1266    1\n",
              "1267    1\n",
              "1268    3\n",
              "1269    3\n",
              "1270    3\n",
              "1271    3\n",
              "1272    4\n",
              "1273    3\n",
              "1274    3\n",
              "1275    3\n",
              "1276    3\n",
              "1277    3\n",
              "1278    3\n",
              "1279    2\n",
              "Name: 72, Length: 1280, dtype: int32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh8x0fq2jKvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras import backend as K\n",
        "# K.set_image_dim_ordering('tf')\n",
        "# def make_model():\n",
        "  \n",
        "#   num_category = 2\n",
        "#   # t_train=y_train\n",
        "#   # y_test=y_val\n",
        "#   # y_train = keras.utils.to_categorical(y_train, num_category)\n",
        "#   # y_test = keras.utils.to_categorical(y_val, num_category)\n",
        "#   model = Sequential()\n",
        "#   #convolutional layer with rectified linear unit activation\n",
        "#   model.add(Conv2D(32, kernel_size=3,activation='relu',input_shape=(32,32,1), \n",
        "#                    kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.1), bias_initializer=keras.initializers.Constant(value=0.1)))\n",
        "#   #32 convolution filters used each of size 3x3\n",
        "#   #again\n",
        "#   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#   model.add(BatchNormalization())\n",
        "# #   model.add(Dropout(0.1))\n",
        "#   model.add(Conv2D(64, 3, activation='relu',kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.1), bias_initializer=keras.initializers.Constant(value=0.1)))\n",
        "#   model.add(Conv2D(64, kernel_size=3,activation='relu',kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.1), bias_initializer=keras.initializers.Constant(value=0.1)))\n",
        "#   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#   #64 convolution filters used each of size 3x3\n",
        "#   #choose the best features via pooling\n",
        "# #   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#   model.add(BatchNormalization())\n",
        "\n",
        "#   model.add(Conv2D(128, kernel_size=3,activation='relu',kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.1), bias_initializer=keras.initializers.Constant(value=0.1)))\n",
        "#   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#   model.add(BatchNormalization())\n",
        "  \n",
        "# #   model.add(Dropout(0.2))\n",
        "  \n",
        "# #   model.add(BatchNormalization())\n",
        "# #   model.add(Dropout(0.2))\n",
        "#   # randomly turn neurons on and off to improve convergence\n",
        "#   # model.add(Dropout(0.25))\n",
        "#   # model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "#   # #64 convolution filters used each of size 3x3\n",
        "#   # #choose the best features via pooling\n",
        "#   # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#   # model.add(BatchNormalization())\n",
        "#   # model.add(Dropout(0.2))\n",
        "#   # model.add(Conv2D(512, kernel_size=(3, 3),\n",
        "#   #                  activation='relu'))\n",
        "#   # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#   # model.add(BatchNormalization())\n",
        "#   # model.add(Dropout(0.1))\n",
        "#   # # randomly turn neurons on and off to improve convergence\n",
        "#   # model.add(Dropout(0.25))\n",
        "#   # # flatten since too many dimensions, we only want a classification output\n",
        "#   model.add(Flatten())\n",
        "#   #fully connected to get all relevant data\n",
        "#   model.add(Dense(256, activation='relu'))\n",
        "#   #one more dropout for convergence' sake :) \n",
        "# #   model.add(Dropout(0.2))\n",
        "#   #output a softmax to squash the matrix into output probabilities\n",
        "#   model.add(Dense(2, activation='softmax'))\n",
        "#   print(model.summary())\n",
        "#   model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adadelta(),\n",
        "#               metrics=['accuracy'])\n",
        "#   return model\n",
        "# # model=make_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtUC5bFAjcYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adadelta(),\n",
        "#               metrics=['accuracy'])\n",
        "# X_test=to_categorical(X_test)\n",
        "# y_test=to_categorical(y_test)\n",
        "# batch_size = 256\n",
        "# num_epoch = 100\n",
        "# model_log = model.fit(X_train, y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=num_epoch,\n",
        "#           verbose=1,\n",
        "#           validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCa9hxbHkxU1",
        "colab_type": "code",
        "outputId": "cf04b325-2bad-4cab-f8c6-0b029ede5df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "def make_model():\n",
        "  n_cols=X_train.shape[1]\n",
        "  model=Sequential()\n",
        "  model.add(Dense(664, kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
        "                bias_initializer=keras.initializers.Constant(value=0.1),activation='relu',input_shape=(n_cols,)))\n",
        "  model.add(Dense(664, kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
        "                bias_initializer=keras.initializers.Constant(value=0.1),activation='relu'))\n",
        "  model.add(Dense(664,activation='relu'))\n",
        "  model.add(Dense(664,activation='relu'))\n",
        "  model.add(Dense(332,activation='relu'))\n",
        "  model.add(Dense(166,activation='relu'))\n",
        "  model.add(Dense(83,activation='relu'))\n",
        "  model.add(Dense(42,activation='relu'))\n",
        "  model.add(Dense(21,activation='relu'))\n",
        "  model.add(Dense(10,activation='relu'))\n",
        "  model.add(Dense(4,activation='softmax')) \n",
        "#   model.add(Dense(2,activation='softmax'))\n",
        "  #model.add(Dense(2,activation='softmax'))\n",
        "  model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(.001),\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model=make_model()\n",
        "model.summary()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_711 (Dense)            (None, 664)               49136     \n",
            "_________________________________________________________________\n",
            "dense_712 (Dense)            (None, 664)               441560    \n",
            "_________________________________________________________________\n",
            "dense_713 (Dense)            (None, 664)               441560    \n",
            "_________________________________________________________________\n",
            "dense_714 (Dense)            (None, 664)               441560    \n",
            "_________________________________________________________________\n",
            "dense_715 (Dense)            (None, 332)               220780    \n",
            "_________________________________________________________________\n",
            "dense_716 (Dense)            (None, 166)               55278     \n",
            "_________________________________________________________________\n",
            "dense_717 (Dense)            (None, 83)                13861     \n",
            "_________________________________________________________________\n",
            "dense_718 (Dense)            (None, 42)                3528      \n",
            "_________________________________________________________________\n",
            "dense_719 (Dense)            (None, 21)                903       \n",
            "_________________________________________________________________\n",
            "dense_720 (Dense)            (None, 10)                220       \n",
            "_________________________________________________________________\n",
            "dense_721 (Dense)            (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 1,668,430\n",
            "Trainable params: 1,668,430\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyt2spx9jpxN",
        "colab_type": "code",
        "outputId": "bb478c4b-3629-478f-c912-127c2cf29eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('cnn', KerasClassifier(build_fn=make_model, epochs=50, batch_size=256, verbose=1, shuffle=True)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "results = cross_val_score(pipeline, X_train,y_train, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1022/1022 [==============================] - 10s 9ms/step - loss: 1.3661 - acc: 0.3611\n",
            "Epoch 2/50\n",
            "1022/1022 [==============================] - 0s 44us/step - loss: 1.2966 - acc: 0.4149\n",
            "Epoch 3/50\n",
            "1022/1022 [==============================] - 0s 46us/step - loss: 1.2050 - acc: 0.4149\n",
            "Epoch 4/50\n",
            "1022/1022 [==============================] - 0s 43us/step - loss: 0.9706 - acc: 0.4384\n",
            "Epoch 5/50\n",
            "1022/1022 [==============================] - 0s 42us/step - loss: 0.7765 - acc: 0.6810\n",
            "Epoch 6/50\n",
            "1022/1022 [==============================] - 0s 43us/step - loss: 0.5300 - acc: 0.8679\n",
            "Epoch 7/50\n",
            "1022/1022 [==============================] - 0s 43us/step - loss: 0.3263 - acc: 0.9012\n",
            "Epoch 8/50\n",
            "1022/1022 [==============================] - 0s 42us/step - loss: 0.3819 - acc: 0.8591\n",
            "Epoch 9/50\n",
            "1022/1022 [==============================] - 0s 44us/step - loss: 0.3442 - acc: 0.8376\n",
            "Epoch 10/50\n",
            "1022/1022 [==============================] - 0s 42us/step - loss: 0.1990 - acc: 0.9149\n",
            "Epoch 11/50\n",
            "1022/1022 [==============================] - 0s 41us/step - loss: 0.1467 - acc: 0.9501\n",
            "Epoch 12/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 0.0771 - acc: 0.9883\n",
            "Epoch 13/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 0.0507 - acc: 0.9902\n",
            "Epoch 14/50\n",
            "1022/1022 [==============================] - 0s 41us/step - loss: 0.0229 - acc: 0.9941\n",
            "Epoch 15/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 0.0104 - acc: 0.9990\n",
            "Epoch 16/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 0.0060 - acc: 0.9971\n",
            "Epoch 17/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 0.0061 - acc: 0.9990\n",
            "Epoch 18/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1022/1022 [==============================] - 0s 41us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 8.7845e-04 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 4.9577e-04 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1022/1022 [==============================] - 0s 38us/step - loss: 3.6684e-04 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1022/1022 [==============================] - 0s 38us/step - loss: 3.1918e-04 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 2.8670e-04 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1022/1022 [==============================] - 0s 42us/step - loss: 2.5628e-04 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1022/1022 [==============================] - 0s 46us/step - loss: 2.2795e-04 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 2.0421e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1022/1022 [==============================] - 0s 37us/step - loss: 1.8577e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1022/1022 [==============================] - 0s 38us/step - loss: 1.6928e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 1.5475e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1022/1022 [==============================] - 0s 38us/step - loss: 1.3875e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 1.2278e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1022/1022 [==============================] - 0s 42us/step - loss: 1.1059e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1022/1022 [==============================] - 0s 41us/step - loss: 9.9276e-05 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1022/1022 [==============================] - 0s 41us/step - loss: 8.9110e-05 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1022/1022 [==============================] - 0s 41us/step - loss: 8.1401e-05 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 7.4508e-05 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 6.8405e-05 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1022/1022 [==============================] - 0s 38us/step - loss: 6.3513e-05 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 5.9107e-05 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 5.5322e-05 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 5.2077e-05 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1022/1022 [==============================] - 0s 42us/step - loss: 4.8973e-05 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 4.6325e-05 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 4.3863e-05 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1022/1022 [==============================] - 0s 39us/step - loss: 4.1512e-05 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1022/1022 [==============================] - 0s 40us/step - loss: 3.9322e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1022/1022 [==============================] - 0s 38us/step - loss: 3.7253e-05 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1022/1022 [==============================] - 0s 41us/step - loss: 3.5281e-05 - acc: 1.0000\n",
            "258/258 [==============================] - 4s 15ms/step\n",
            "Epoch 1/50\n",
            "1023/1023 [==============================] - 10s 9ms/step - loss: 1.3369 - acc: 0.3969\n",
            "Epoch 2/50\n",
            "1023/1023 [==============================] - 0s 43us/step - loss: 1.2593 - acc: 0.4154\n",
            "Epoch 3/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 1.1196 - acc: 0.4154\n",
            "Epoch 4/50\n",
            "1023/1023 [==============================] - 0s 42us/step - loss: 0.9350 - acc: 0.4448\n",
            "Epoch 5/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.8322 - acc: 0.5679\n",
            "Epoch 6/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.8112 - acc: 0.7028\n",
            "Epoch 7/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.8068 - acc: 0.6393\n",
            "Epoch 8/50\n",
            "1023/1023 [==============================] - 0s 42us/step - loss: 0.7772 - acc: 0.6452\n",
            "Epoch 9/50\n",
            "1023/1023 [==============================] - 0s 43us/step - loss: 0.7624 - acc: 0.6764\n",
            "Epoch 10/50\n",
            "1023/1023 [==============================] - 0s 42us/step - loss: 0.6686 - acc: 0.7263\n",
            "Epoch 11/50\n",
            "1023/1023 [==============================] - 0s 40us/step - loss: 0.6185 - acc: 0.7273\n",
            "Epoch 12/50\n",
            "1023/1023 [==============================] - 0s 40us/step - loss: 0.5945 - acc: 0.7722\n",
            "Epoch 13/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 0.6401 - acc: 0.7370\n",
            "Epoch 14/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 0.6033 - acc: 0.7889\n",
            "Epoch 15/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.5580 - acc: 0.7683\n",
            "Epoch 16/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 0.4993 - acc: 0.7810\n",
            "Epoch 17/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.3642 - acc: 0.7742\n",
            "Epoch 18/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.2956 - acc: 0.7693\n",
            "Epoch 19/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.7103 - acc: 0.6686\n",
            "Epoch 20/50\n",
            "1023/1023 [==============================] - 0s 44us/step - loss: 0.5933 - acc: 0.6393\n",
            "Epoch 21/50\n",
            "1023/1023 [==============================] - 0s 44us/step - loss: 0.3587 - acc: 0.9365\n",
            "Epoch 22/50\n",
            "1023/1023 [==============================] - 0s 40us/step - loss: 0.3036 - acc: 0.9482\n",
            "Epoch 23/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 0.2386 - acc: 0.9629\n",
            "Epoch 24/50\n",
            "1023/1023 [==============================] - 0s 40us/step - loss: 0.1747 - acc: 0.9941\n",
            "Epoch 25/50\n",
            "1023/1023 [==============================] - 0s 42us/step - loss: 0.1081 - acc: 0.9863\n",
            "Epoch 26/50\n",
            "1023/1023 [==============================] - 0s 40us/step - loss: 0.0528 - acc: 0.9990\n",
            "Epoch 27/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.0227 - acc: 0.9990\n",
            "Epoch 28/50\n",
            "1023/1023 [==============================] - 0s 43us/step - loss: 0.0105 - acc: 0.9990\n",
            "Epoch 29/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 0.0037 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1023/1023 [==============================] - 0s 40us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1023/1023 [==============================] - 0s 38us/step - loss: 6.4910e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1023/1023 [==============================] - 0s 40us/step - loss: 4.1473e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1023/1023 [==============================] - 0s 42us/step - loss: 2.7293e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 2.0963e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 1.6282e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1023/1023 [==============================] - 0s 38us/step - loss: 1.3099e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 1.1269e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 1.0448e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 9.6295e-05 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1023/1023 [==============================] - 0s 38us/step - loss: 8.9290e-05 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 8.3740e-05 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1023/1023 [==============================] - 0s 41us/step - loss: 7.9057e-05 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1023/1023 [==============================] - 0s 44us/step - loss: 7.5746e-05 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1023/1023 [==============================] - 0s 43us/step - loss: 7.2610e-05 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1023/1023 [==============================] - 0s 43us/step - loss: 6.9769e-05 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 6.7306e-05 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 6.4803e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1023/1023 [==============================] - 0s 38us/step - loss: 6.2803e-05 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1023/1023 [==============================] - 0s 39us/step - loss: 6.0845e-05 - acc: 1.0000\n",
            "257/257 [==============================] - 4s 16ms/step\n",
            "Epoch 1/50\n",
            "1025/1025 [==============================] - 10s 10ms/step - loss: 1.3096 - acc: 0.4000\n",
            "Epoch 2/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.2615 - acc: 0.4146\n",
            "Epoch 3/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.2044 - acc: 0.4146\n",
            "Epoch 4/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 1.0653 - acc: 0.4146\n",
            "Epoch 5/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.9585 - acc: 0.4146\n",
            "Epoch 6/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.8737 - acc: 0.4761\n",
            "Epoch 7/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 0.8477 - acc: 0.6107\n",
            "Epoch 8/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.8141 - acc: 0.4761\n",
            "Epoch 9/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.7472 - acc: 0.5961\n",
            "Epoch 10/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.7592 - acc: 0.6224\n",
            "Epoch 11/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.5062 - acc: 0.7932\n",
            "Epoch 12/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 1.3245 - acc: 0.5171\n",
            "Epoch 13/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 1.0016 - acc: 0.3502\n",
            "Epoch 14/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.8301 - acc: 0.5717\n",
            "Epoch 15/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.8185 - acc: 0.5200\n",
            "Epoch 16/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.7983 - acc: 0.6927\n",
            "Epoch 17/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.7871 - acc: 0.6624\n",
            "Epoch 18/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.7700 - acc: 0.7493\n",
            "Epoch 19/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.7584 - acc: 0.7766\n",
            "Epoch 20/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.6978 - acc: 0.7932\n",
            "Epoch 21/50\n",
            "1025/1025 [==============================] - 0s 57us/step - loss: 0.7010 - acc: 0.6693\n",
            "Epoch 22/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.6969 - acc: 0.6849\n",
            "Epoch 23/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.5549 - acc: 0.8020\n",
            "Epoch 24/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.3959 - acc: 0.8576\n",
            "Epoch 25/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.2570 - acc: 0.8673\n",
            "Epoch 26/50\n",
            "1025/1025 [==============================] - 0s 53us/step - loss: 0.2196 - acc: 0.8429\n",
            "Epoch 27/50\n",
            "1025/1025 [==============================] - 0s 55us/step - loss: 0.1924 - acc: 0.8459\n",
            "Epoch 28/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.4609 - acc: 0.7746\n",
            "Epoch 29/50\n",
            "1025/1025 [==============================] - 0s 46us/step - loss: 2.7476 - acc: 0.6098\n",
            "Epoch 30/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.3477 - acc: 0.2917\n",
            "Epoch 31/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 1.3457 - acc: 0.1795\n",
            "Epoch 32/50\n",
            "1025/1025 [==============================] - 0s 53us/step - loss: 1.3966 - acc: 0.1659\n",
            "Epoch 33/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.3958 - acc: 0.2312\n",
            "Epoch 34/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.3889 - acc: 0.2341\n",
            "Epoch 35/50\n",
            "1025/1025 [==============================] - 0s 46us/step - loss: 1.3642 - acc: 0.2566\n",
            "Epoch 36/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.2275 - acc: 0.3941\n",
            "Epoch 37/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 1.0166 - acc: 0.5873\n",
            "Epoch 38/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.9003 - acc: 0.6146\n",
            "Epoch 39/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.8921 - acc: 0.6010\n",
            "Epoch 40/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.8863 - acc: 0.6020\n",
            "Epoch 41/50\n",
            "1025/1025 [==============================] - 0s 59us/step - loss: 0.8350 - acc: 0.6400\n",
            "Epoch 42/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.8068 - acc: 0.6429\n",
            "Epoch 43/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.8009 - acc: 0.6410\n",
            "Epoch 44/50\n",
            "1025/1025 [==============================] - 0s 46us/step - loss: 0.7948 - acc: 0.6420\n",
            "Epoch 45/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.7912 - acc: 0.6459\n",
            "Epoch 46/50\n",
            "1025/1025 [==============================] - 0s 56us/step - loss: 0.7867 - acc: 0.6488\n",
            "Epoch 47/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.7730 - acc: 0.6712\n",
            "Epoch 48/50\n",
            "1025/1025 [==============================] - 0s 45us/step - loss: 0.7116 - acc: 0.7649\n",
            "Epoch 49/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.7307 - acc: 0.7551\n",
            "Epoch 50/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 0.6884 - acc: 0.7717\n",
            "255/255 [==============================] - 4s 16ms/step\n",
            "Epoch 1/50\n",
            "1025/1025 [==============================] - 10s 10ms/step - loss: 1.3811 - acc: 0.2244\n",
            "Epoch 2/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 1.3398 - acc: 0.3629\n",
            "Epoch 3/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.3309 - acc: 0.2234\n",
            "Epoch 4/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.2599 - acc: 0.4146\n",
            "Epoch 5/50\n",
            "1025/1025 [==============================] - 0s 54us/step - loss: 1.1643 - acc: 0.4146\n",
            "Epoch 6/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.0260 - acc: 0.4146\n",
            "Epoch 7/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 0.9549 - acc: 0.4146\n",
            "Epoch 8/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.8827 - acc: 0.5610\n",
            "Epoch 9/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.7552 - acc: 0.5854\n",
            "Epoch 10/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.6666 - acc: 0.6312\n",
            "Epoch 11/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.5004 - acc: 0.7639\n",
            "Epoch 12/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.7703 - acc: 0.6068\n",
            "Epoch 13/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.6480 - acc: 0.6780\n",
            "Epoch 14/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 0.4903 - acc: 0.7902\n",
            "Epoch 15/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.3233 - acc: 0.8644\n",
            "Epoch 16/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.1731 - acc: 0.9688\n",
            "Epoch 17/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.0780 - acc: 0.9951\n",
            "Epoch 18/50\n",
            "1025/1025 [==============================] - 0s 46us/step - loss: 0.0423 - acc: 0.9922\n",
            "Epoch 19/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0205 - acc: 0.9980\n",
            "Epoch 20/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.0173 - acc: 0.9971\n",
            "Epoch 21/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.1977 - acc: 0.9463\n",
            "Epoch 22/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.2269 - acc: 0.9483\n",
            "Epoch 23/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.5793 - acc: 0.8127\n",
            "Epoch 24/50\n",
            "1025/1025 [==============================] - 0s 53us/step - loss: 0.1643 - acc: 0.9512\n",
            "Epoch 25/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.1041 - acc: 0.9639\n",
            "Epoch 26/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.1052 - acc: 0.9678\n",
            "Epoch 27/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.0598 - acc: 0.9863\n",
            "Epoch 28/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.0195 - acc: 0.9961\n",
            "Epoch 29/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.0065 - acc: 0.9971\n",
            "Epoch 30/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.0045 - acc: 0.9980\n",
            "Epoch 32/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 9.2987e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1025/1025 [==============================] - 0s 53us/step - loss: 3.0978e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 2.9617e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 2.8341e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 2.1966e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.7275e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 1.5243e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 1.4008e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 1.2924e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.2100e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1025/1025 [==============================] - 0s 55us/step - loss: 1.1377e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 1.0753e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 1.0217e-04 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 9.7463e-05 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 9.3217e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 8.9374e-05 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 8.5912e-05 - acc: 1.0000\n",
            "255/255 [==============================] - 4s 16ms/step\n",
            "Epoch 1/50\n",
            "1025/1025 [==============================] - 10s 10ms/step - loss: 1.3950 - acc: 0.2459\n",
            "Epoch 2/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 1.3210 - acc: 0.4146\n",
            "Epoch 3/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 1.2794 - acc: 0.4166\n",
            "Epoch 4/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 1.1976 - acc: 0.4839\n",
            "Epoch 5/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 1.0905 - acc: 0.4712\n",
            "Epoch 6/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.9606 - acc: 0.5844\n",
            "Epoch 7/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.6441 - acc: 0.6985\n",
            "Epoch 8/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.3676 - acc: 0.8478\n",
            "Epoch 9/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.3706 - acc: 0.8634\n",
            "Epoch 10/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 2.2781 - acc: 0.4966\n",
            "Epoch 11/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.8336 - acc: 0.6302\n",
            "Epoch 12/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 1.2136 - acc: 0.6000\n",
            "Epoch 13/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.7314 - acc: 0.5873\n",
            "Epoch 14/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.7831 - acc: 0.5678\n",
            "Epoch 15/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.7476 - acc: 0.5737\n",
            "Epoch 16/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.7055 - acc: 0.6761\n",
            "Epoch 17/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.6324 - acc: 0.6917\n",
            "Epoch 18/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.5957 - acc: 0.6839\n",
            "Epoch 19/50\n",
            "1025/1025 [==============================] - 0s 61us/step - loss: 0.4264 - acc: 0.8254\n",
            "Epoch 20/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.2833 - acc: 0.8946\n",
            "Epoch 21/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.1810 - acc: 0.9395\n",
            "Epoch 22/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.1221 - acc: 0.9688\n",
            "Epoch 23/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0763 - acc: 0.9824\n",
            "Epoch 24/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.0475 - acc: 0.9912\n",
            "Epoch 25/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0443 - acc: 0.9922\n",
            "Epoch 26/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0332 - acc: 0.9971\n",
            "Epoch 27/50\n",
            "1025/1025 [==============================] - 0s 55us/step - loss: 0.0239 - acc: 0.9980\n",
            "Epoch 28/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 0.0144 - acc: 0.9980\n",
            "Epoch 29/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.0096 - acc: 0.9990\n",
            "Epoch 30/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0081 - acc: 0.9990\n",
            "Epoch 31/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.0071 - acc: 0.9990\n",
            "Epoch 32/50\n",
            "1025/1025 [==============================] - 0s 52us/step - loss: 0.0062 - acc: 0.9990\n",
            "Epoch 33/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.0053 - acc: 0.9990\n",
            "Epoch 34/50\n",
            "1025/1025 [==============================] - 0s 49us/step - loss: 0.0048 - acc: 0.9990\n",
            "Epoch 35/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.0052 - acc: 0.9990\n",
            "Epoch 36/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.0037 - acc: 0.9990\n",
            "Epoch 37/50\n",
            "1025/1025 [==============================] - 0s 50us/step - loss: 0.0039 - acc: 0.9990\n",
            "Epoch 38/50\n",
            "1025/1025 [==============================] - 0s 55us/step - loss: 0.0045 - acc: 0.9990\n",
            "Epoch 39/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0029 - acc: 0.9990\n",
            "Epoch 40/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0026 - acc: 0.9990\n",
            "Epoch 41/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0022 - acc: 0.9990\n",
            "Epoch 42/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0017 - acc: 0.9990\n",
            "Epoch 43/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1025/1025 [==============================] - 0s 51us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0014 - acc: 0.9990\n",
            "Epoch 47/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0014 - acc: 0.9990\n",
            "Epoch 48/50\n",
            "1025/1025 [==============================] - 0s 47us/step - loss: 0.0017 - acc: 0.9990\n",
            "Epoch 49/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1025/1025 [==============================] - 0s 48us/step - loss: 7.3481e-04 - acc: 1.0000\n",
            "255/255 [==============================] - 4s 16ms/step\n",
            "Results: 93.73% (10.40%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoBjLyscjpzs",
        "colab_type": "code",
        "outputId": "773b5a9a-8319-4195-acf3-5530a7a2abbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99224806, 0.9844358 , 0.72941178, 0.99215686, 0.98823529])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kic50sYEoxF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}